{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RNfoI03pTqe5"
      },
      "outputs": [],
      "source": [
        "!mkdir ~p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2pbg6hgUQcm",
        "outputId": "f310403e-e706-4b94-ccf4-ddb443a34a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
            "License(s): unknown\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 1.06G/1.06G [00:55<00:00, 20.9MB/s]\n",
            "100% 1.06G/1.06G [00:55<00:00, 20.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1PdvkkofUcPL"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2feYIRsAUqHG",
        "outputId": "0e55d8cb-ab2c-4b8b-aa23-c4ae9a4a8af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.5.0-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.5/890.5 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "!pip install torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vUC119YfVAV8"
      },
      "outputs": [],
      "source": [
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize(128),transforms.RandomResizedCrop(128),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "                                     transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225] )])\n",
        "val_transforms=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(128),transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CI04n5r8Vmg6"
      },
      "outputs": [],
      "source": [
        "train_dataset=datasets.ImageFolder('/content/train',transform=train_transforms)\n",
        "val_dataset=datasets.ImageFolder('/content/test',transform=val_transforms)\n",
        "train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8FfwwmW9Vv8n"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self,pretrained=True,num_unfreeze_layers=0):\n",
        "    super(CNNModel, self).__init__()\n",
        "    if pretrained:\n",
        "      self.model=models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
        "      self.model.requires_grad_(False)\n",
        "      if num_unfreeze_layers>0:\n",
        "        num_layers=0\n",
        "        for name, module in self.model.named_modules():\n",
        "                    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.BatchNorm2d):\n",
        "                        num_layers+=1\n",
        "        start_unfreezing_counter,counter=num_layers-num_unfreeze_layers,0\n",
        "        for name, module in self.model.named_modules():\n",
        "                    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.BatchNorm2d):\n",
        "                        counter+=1\n",
        "                    if counter >= start_unfreezing_counter:\n",
        "                        module.requires_grad_(True)\n",
        "      self.model.fc = nn.Linear(512, 500)  # Correctly replace the 1000 output to match your custom FC\n",
        "\n",
        "        # Add a new fully connected layer for your custom classification\n",
        "      self.fc = nn.Sequential(\n",
        "            nn.Linear(500, 500),  # Now matches the modified resnet output\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, 2)  # Assuming 2 output classes\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        # Pass input through ResNet backbone\n",
        "        out = self.model(x)\n",
        "\n",
        "        # Now, `out` has shape [batch_size, 500], already flattened due to the new FC layer in resnet\n",
        "        out = self.fc(out)  # Pass through the new classification head\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K__lslHfwzJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "03LguFMHfwcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d54ab5-42a5-4443-d817-cfaf72d4c114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 197MB/s]\n"
          ]
        }
      ],
      "source": [
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "deep_finetuning_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "deep_finetuning_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = CNNModel(pretrained=True, num_unfreeze_layers=31)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aO6ss71ofaNz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.00001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-KCNvPm5iXXF"
      },
      "outputs": [],
      "source": [
        "import torch.cuda.amp as amp\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, scheduler=None, epochs=20):\n",
        "    scaler = amp.GradScaler()  # Mixed precision scaler\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with amp.autocast():  # Enable mixed precision\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()  # Scale gradients\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)} - Loss: {running_loss/10:.4f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        train_acc_list.append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with amp.autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        val_acc_list.append(val_acc)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    return train_acc_list, val_acc_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i9f3nlB64GMO",
        "outputId": "8d1a9db3-ca5a-4baf-9754-d69dbcbec76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7d7d65bae62a>:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()  # Mixed precision scaler\n",
            "<ipython-input-10-7d7d65bae62a>:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():  # Enable mixed precision\n",
            "<ipython-input-7-dce7cf042faa>:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch 0/625 - Loss: 0.0674\n",
            "Epoch 1/10, Batch 10/625 - Loss: 0.6618\n",
            "Epoch 1/10, Batch 20/625 - Loss: 0.5901\n",
            "Epoch 1/10, Batch 30/625 - Loss: 0.5374\n",
            "Epoch 1/10, Batch 40/625 - Loss: 0.5351\n",
            "Epoch 1/10, Batch 50/625 - Loss: 0.5017\n",
            "Epoch 1/10, Batch 60/625 - Loss: 0.5276\n",
            "Epoch 1/10, Batch 70/625 - Loss: 0.5279\n",
            "Epoch 1/10, Batch 80/625 - Loss: 0.4255\n",
            "Epoch 1/10, Batch 90/625 - Loss: 0.4887\n",
            "Epoch 1/10, Batch 100/625 - Loss: 0.4994\n",
            "Epoch 1/10, Batch 110/625 - Loss: 0.4775\n",
            "Epoch 1/10, Batch 120/625 - Loss: 0.5202\n",
            "Epoch 1/10, Batch 130/625 - Loss: 0.5353\n",
            "Epoch 1/10, Batch 140/625 - Loss: 0.4583\n",
            "Epoch 1/10, Batch 150/625 - Loss: 0.4131\n",
            "Epoch 1/10, Batch 160/625 - Loss: 0.4983\n",
            "Epoch 1/10, Batch 170/625 - Loss: 0.4705\n",
            "Epoch 1/10, Batch 180/625 - Loss: 0.4261\n",
            "Epoch 1/10, Batch 190/625 - Loss: 0.4181\n",
            "Epoch 1/10, Batch 200/625 - Loss: 0.4679\n",
            "Epoch 1/10, Batch 210/625 - Loss: 0.5137\n",
            "Epoch 1/10, Batch 220/625 - Loss: 0.4035\n",
            "Epoch 1/10, Batch 230/625 - Loss: 0.4581\n",
            "Epoch 1/10, Batch 240/625 - Loss: 0.4274\n",
            "Epoch 1/10, Batch 250/625 - Loss: 0.3869\n",
            "Epoch 1/10, Batch 260/625 - Loss: 0.4232\n",
            "Epoch 1/10, Batch 270/625 - Loss: 0.4685\n",
            "Epoch 1/10, Batch 280/625 - Loss: 0.5218\n",
            "Epoch 1/10, Batch 290/625 - Loss: 0.4351\n",
            "Epoch 1/10, Batch 300/625 - Loss: 0.3988\n",
            "Epoch 1/10, Batch 310/625 - Loss: 0.4374\n",
            "Epoch 1/10, Batch 320/625 - Loss: 0.4155\n",
            "Epoch 1/10, Batch 330/625 - Loss: 0.4200\n",
            "Epoch 1/10, Batch 340/625 - Loss: 0.4334\n",
            "Epoch 1/10, Batch 350/625 - Loss: 0.4552\n",
            "Epoch 1/10, Batch 360/625 - Loss: 0.3691\n",
            "Epoch 1/10, Batch 370/625 - Loss: 0.5262\n",
            "Epoch 1/10, Batch 380/625 - Loss: 0.4779\n",
            "Epoch 1/10, Batch 390/625 - Loss: 0.4479\n",
            "Epoch 1/10, Batch 400/625 - Loss: 0.4557\n",
            "Epoch 1/10, Batch 410/625 - Loss: 0.3669\n",
            "Epoch 1/10, Batch 420/625 - Loss: 0.3814\n",
            "Epoch 1/10, Batch 430/625 - Loss: 0.4121\n",
            "Epoch 1/10, Batch 440/625 - Loss: 0.4117\n",
            "Epoch 1/10, Batch 450/625 - Loss: 0.3875\n",
            "Epoch 1/10, Batch 460/625 - Loss: 0.4114\n",
            "Epoch 1/10, Batch 470/625 - Loss: 0.4413\n",
            "Epoch 1/10, Batch 480/625 - Loss: 0.4343\n",
            "Epoch 1/10, Batch 490/625 - Loss: 0.3891\n",
            "Epoch 1/10, Batch 500/625 - Loss: 0.4006\n",
            "Epoch 1/10, Batch 510/625 - Loss: 0.5041\n",
            "Epoch 1/10, Batch 520/625 - Loss: 0.3909\n",
            "Epoch 1/10, Batch 530/625 - Loss: 0.4152\n",
            "Epoch 1/10, Batch 540/625 - Loss: 0.4655\n",
            "Epoch 1/10, Batch 550/625 - Loss: 0.4893\n",
            "Epoch 1/10, Batch 560/625 - Loss: 0.4006\n",
            "Epoch 1/10, Batch 570/625 - Loss: 0.3854\n",
            "Epoch 1/10, Batch 580/625 - Loss: 0.4185\n",
            "Epoch 1/10, Batch 590/625 - Loss: 0.4180\n",
            "Epoch 1/10, Batch 600/625 - Loss: 0.3890\n",
            "Epoch 1/10, Batch 610/625 - Loss: 0.4183\n",
            "Epoch 1/10, Batch 620/625 - Loss: 0.4379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7d7d65bae62a>:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Acc: 78.74%, Val Acc: 90.12%, Val Loss: 0.2426\n",
            "Epoch 2/10, Batch 0/625 - Loss: 0.0275\n",
            "Epoch 2/10, Batch 10/625 - Loss: 0.3353\n",
            "Epoch 2/10, Batch 20/625 - Loss: 0.4039\n",
            "Epoch 2/10, Batch 30/625 - Loss: 0.3169\n",
            "Epoch 2/10, Batch 40/625 - Loss: 0.3747\n",
            "Epoch 2/10, Batch 50/625 - Loss: 0.3508\n",
            "Epoch 2/10, Batch 60/625 - Loss: 0.3310\n",
            "Epoch 2/10, Batch 70/625 - Loss: 0.4492\n",
            "Epoch 2/10, Batch 80/625 - Loss: 0.3974\n",
            "Epoch 2/10, Batch 90/625 - Loss: 0.3200\n",
            "Epoch 2/10, Batch 100/625 - Loss: 0.4189\n",
            "Epoch 2/10, Batch 110/625 - Loss: 0.3951\n",
            "Epoch 2/10, Batch 120/625 - Loss: 0.4997\n",
            "Epoch 2/10, Batch 130/625 - Loss: 0.3626\n",
            "Epoch 2/10, Batch 140/625 - Loss: 0.4011\n",
            "Epoch 2/10, Batch 150/625 - Loss: 0.3429\n",
            "Epoch 2/10, Batch 160/625 - Loss: 0.3868\n",
            "Epoch 2/10, Batch 170/625 - Loss: 0.3954\n",
            "Epoch 2/10, Batch 180/625 - Loss: 0.3776\n",
            "Epoch 2/10, Batch 190/625 - Loss: 0.3821\n",
            "Epoch 2/10, Batch 200/625 - Loss: 0.3473\n",
            "Epoch 2/10, Batch 210/625 - Loss: 0.3942\n",
            "Epoch 2/10, Batch 220/625 - Loss: 0.3959\n",
            "Epoch 2/10, Batch 230/625 - Loss: 0.4364\n",
            "Epoch 2/10, Batch 240/625 - Loss: 0.3943\n",
            "Epoch 2/10, Batch 250/625 - Loss: 0.4103\n",
            "Epoch 2/10, Batch 260/625 - Loss: 0.3688\n",
            "Epoch 2/10, Batch 270/625 - Loss: 0.4041\n",
            "Epoch 2/10, Batch 280/625 - Loss: 0.3312\n",
            "Epoch 2/10, Batch 290/625 - Loss: 0.3526\n",
            "Epoch 2/10, Batch 300/625 - Loss: 0.3486\n",
            "Epoch 2/10, Batch 310/625 - Loss: 0.4005\n",
            "Epoch 2/10, Batch 320/625 - Loss: 0.3001\n",
            "Epoch 2/10, Batch 330/625 - Loss: 0.3656\n",
            "Epoch 2/10, Batch 340/625 - Loss: 0.3579\n",
            "Epoch 2/10, Batch 350/625 - Loss: 0.2925\n",
            "Epoch 2/10, Batch 360/625 - Loss: 0.4045\n",
            "Epoch 2/10, Batch 370/625 - Loss: 0.4353\n",
            "Epoch 2/10, Batch 380/625 - Loss: 0.4063\n",
            "Epoch 2/10, Batch 390/625 - Loss: 0.3719\n",
            "Epoch 2/10, Batch 400/625 - Loss: 0.3729\n",
            "Epoch 2/10, Batch 410/625 - Loss: 0.3999\n",
            "Epoch 2/10, Batch 420/625 - Loss: 0.3278\n",
            "Epoch 2/10, Batch 430/625 - Loss: 0.3838\n",
            "Epoch 2/10, Batch 440/625 - Loss: 0.3440\n",
            "Epoch 2/10, Batch 450/625 - Loss: 0.4040\n",
            "Epoch 2/10, Batch 460/625 - Loss: 0.3344\n",
            "Epoch 2/10, Batch 470/625 - Loss: 0.3720\n",
            "Epoch 2/10, Batch 480/625 - Loss: 0.3724\n",
            "Epoch 2/10, Batch 490/625 - Loss: 0.3476\n",
            "Epoch 2/10, Batch 500/625 - Loss: 0.3266\n",
            "Epoch 2/10, Batch 510/625 - Loss: 0.3660\n",
            "Epoch 2/10, Batch 520/625 - Loss: 0.3333\n",
            "Epoch 2/10, Batch 530/625 - Loss: 0.3412\n",
            "Epoch 2/10, Batch 540/625 - Loss: 0.3086\n",
            "Epoch 2/10, Batch 550/625 - Loss: 0.3718\n",
            "Epoch 2/10, Batch 560/625 - Loss: 0.3930\n",
            "Epoch 2/10, Batch 570/625 - Loss: 0.3379\n",
            "Epoch 2/10, Batch 580/625 - Loss: 0.3856\n",
            "Epoch 2/10, Batch 590/625 - Loss: 0.3686\n",
            "Epoch 2/10, Batch 600/625 - Loss: 0.3548\n",
            "Epoch 2/10, Batch 610/625 - Loss: 0.4063\n",
            "Epoch 2/10, Batch 620/625 - Loss: 0.3681\n",
            "Epoch [2/10], Train Acc: 83.23%, Val Acc: 92.68%, Val Loss: 0.1893\n",
            "Epoch 3/10, Batch 0/625 - Loss: 0.0408\n",
            "Epoch 3/10, Batch 10/625 - Loss: 0.4306\n",
            "Epoch 3/10, Batch 20/625 - Loss: 0.3533\n",
            "Epoch 3/10, Batch 30/625 - Loss: 0.4323\n",
            "Epoch 3/10, Batch 40/625 - Loss: 0.3929\n",
            "Epoch 3/10, Batch 50/625 - Loss: 0.3398\n",
            "Epoch 3/10, Batch 60/625 - Loss: 0.3046\n",
            "Epoch 3/10, Batch 70/625 - Loss: 0.3486\n",
            "Epoch 3/10, Batch 80/625 - Loss: 0.3659\n",
            "Epoch 3/10, Batch 90/625 - Loss: 0.3749\n",
            "Epoch 3/10, Batch 100/625 - Loss: 0.3056\n",
            "Epoch 3/10, Batch 110/625 - Loss: 0.3140\n",
            "Epoch 3/10, Batch 120/625 - Loss: 0.2927\n",
            "Epoch 3/10, Batch 130/625 - Loss: 0.3872\n",
            "Epoch 3/10, Batch 140/625 - Loss: 0.3134\n",
            "Epoch 3/10, Batch 150/625 - Loss: 0.3654\n",
            "Epoch 3/10, Batch 160/625 - Loss: 0.4191\n",
            "Epoch 3/10, Batch 170/625 - Loss: 0.3074\n",
            "Epoch 3/10, Batch 180/625 - Loss: 0.3978\n",
            "Epoch 3/10, Batch 190/625 - Loss: 0.3594\n",
            "Epoch 3/10, Batch 200/625 - Loss: 0.2885\n",
            "Epoch 3/10, Batch 210/625 - Loss: 0.3107\n",
            "Epoch 3/10, Batch 220/625 - Loss: 0.3830\n",
            "Epoch 3/10, Batch 230/625 - Loss: 0.3092\n",
            "Epoch 3/10, Batch 240/625 - Loss: 0.3499\n",
            "Epoch 3/10, Batch 250/625 - Loss: 0.2713\n",
            "Epoch 3/10, Batch 260/625 - Loss: 0.3849\n",
            "Epoch 3/10, Batch 270/625 - Loss: 0.3237\n",
            "Epoch 3/10, Batch 280/625 - Loss: 0.3310\n",
            "Epoch 3/10, Batch 290/625 - Loss: 0.3352\n",
            "Epoch 3/10, Batch 300/625 - Loss: 0.3183\n",
            "Epoch 3/10, Batch 310/625 - Loss: 0.2956\n",
            "Epoch 3/10, Batch 320/625 - Loss: 0.3505\n",
            "Epoch 3/10, Batch 330/625 - Loss: 0.3247\n",
            "Epoch 3/10, Batch 340/625 - Loss: 0.2965\n",
            "Epoch 3/10, Batch 350/625 - Loss: 0.3151\n",
            "Epoch 3/10, Batch 360/625 - Loss: 0.3539\n",
            "Epoch 3/10, Batch 370/625 - Loss: 0.3281\n",
            "Epoch 3/10, Batch 380/625 - Loss: 0.2788\n",
            "Epoch 3/10, Batch 390/625 - Loss: 0.3638\n",
            "Epoch 3/10, Batch 400/625 - Loss: 0.4309\n",
            "Epoch 3/10, Batch 410/625 - Loss: 0.3141\n",
            "Epoch 3/10, Batch 420/625 - Loss: 0.3391\n",
            "Epoch 3/10, Batch 430/625 - Loss: 0.3762\n",
            "Epoch 3/10, Batch 440/625 - Loss: 0.3692\n",
            "Epoch 3/10, Batch 450/625 - Loss: 0.2983\n",
            "Epoch 3/10, Batch 460/625 - Loss: 0.3422\n",
            "Epoch 3/10, Batch 470/625 - Loss: 0.2999\n",
            "Epoch 3/10, Batch 480/625 - Loss: 0.3963\n",
            "Epoch 3/10, Batch 490/625 - Loss: 0.3452\n",
            "Epoch 3/10, Batch 500/625 - Loss: 0.3020\n",
            "Epoch 3/10, Batch 510/625 - Loss: 0.3449\n",
            "Epoch 3/10, Batch 520/625 - Loss: 0.3075\n",
            "Epoch 3/10, Batch 530/625 - Loss: 0.3847\n",
            "Epoch 3/10, Batch 540/625 - Loss: 0.3703\n",
            "Epoch 3/10, Batch 550/625 - Loss: 0.3598\n",
            "Epoch 3/10, Batch 560/625 - Loss: 0.3659\n",
            "Epoch 3/10, Batch 570/625 - Loss: 0.3040\n",
            "Epoch 3/10, Batch 580/625 - Loss: 0.3296\n",
            "Epoch 3/10, Batch 590/625 - Loss: 0.3047\n",
            "Epoch 3/10, Batch 600/625 - Loss: 0.3199\n",
            "Epoch 3/10, Batch 610/625 - Loss: 0.3745\n",
            "Epoch 3/10, Batch 620/625 - Loss: 0.2921\n",
            "Epoch [3/10], Train Acc: 84.81%, Val Acc: 90.26%, Val Loss: 0.2116\n",
            "Epoch 4/10, Batch 0/625 - Loss: 0.0295\n",
            "Epoch 4/10, Batch 10/625 - Loss: 0.3007\n",
            "Epoch 4/10, Batch 20/625 - Loss: 0.3017\n",
            "Epoch 4/10, Batch 30/625 - Loss: 0.3023\n",
            "Epoch 4/10, Batch 40/625 - Loss: 0.3292\n",
            "Epoch 4/10, Batch 50/625 - Loss: 0.3618\n",
            "Epoch 4/10, Batch 60/625 - Loss: 0.3363\n",
            "Epoch 4/10, Batch 70/625 - Loss: 0.3417\n",
            "Epoch 4/10, Batch 80/625 - Loss: 0.2965\n",
            "Epoch 4/10, Batch 90/625 - Loss: 0.3709\n",
            "Epoch 4/10, Batch 100/625 - Loss: 0.3044\n",
            "Epoch 4/10, Batch 110/625 - Loss: 0.3384\n",
            "Epoch 4/10, Batch 120/625 - Loss: 0.2691\n",
            "Epoch 4/10, Batch 130/625 - Loss: 0.3283\n",
            "Epoch 4/10, Batch 140/625 - Loss: 0.3595\n",
            "Epoch 4/10, Batch 150/625 - Loss: 0.3316\n",
            "Epoch 4/10, Batch 160/625 - Loss: 0.3512\n",
            "Epoch 4/10, Batch 170/625 - Loss: 0.3241\n",
            "Epoch 4/10, Batch 180/625 - Loss: 0.2943\n",
            "Epoch 4/10, Batch 190/625 - Loss: 0.2894\n",
            "Epoch 4/10, Batch 200/625 - Loss: 0.2745\n",
            "Epoch 4/10, Batch 210/625 - Loss: 0.2865\n",
            "Epoch 4/10, Batch 220/625 - Loss: 0.3325\n",
            "Epoch 4/10, Batch 230/625 - Loss: 0.2672\n",
            "Epoch 4/10, Batch 240/625 - Loss: 0.4168\n",
            "Epoch 4/10, Batch 250/625 - Loss: 0.2826\n",
            "Epoch 4/10, Batch 260/625 - Loss: 0.3083\n",
            "Epoch 4/10, Batch 270/625 - Loss: 0.3277\n",
            "Epoch 4/10, Batch 280/625 - Loss: 0.3232\n",
            "Epoch 4/10, Batch 290/625 - Loss: 0.2906\n",
            "Epoch 4/10, Batch 300/625 - Loss: 0.3339\n",
            "Epoch 4/10, Batch 310/625 - Loss: 0.3739\n",
            "Epoch 4/10, Batch 320/625 - Loss: 0.3286\n",
            "Epoch 4/10, Batch 330/625 - Loss: 0.2832\n",
            "Epoch 4/10, Batch 340/625 - Loss: 0.2984\n",
            "Epoch 4/10, Batch 350/625 - Loss: 0.3683\n",
            "Epoch 4/10, Batch 360/625 - Loss: 0.3504\n",
            "Epoch 4/10, Batch 370/625 - Loss: 0.3725\n",
            "Epoch 4/10, Batch 380/625 - Loss: 0.3489\n",
            "Epoch 4/10, Batch 390/625 - Loss: 0.3040\n",
            "Epoch 4/10, Batch 400/625 - Loss: 0.3073\n",
            "Epoch 4/10, Batch 410/625 - Loss: 0.3354\n",
            "Epoch 4/10, Batch 420/625 - Loss: 0.2929\n",
            "Epoch 4/10, Batch 430/625 - Loss: 0.3085\n",
            "Epoch 4/10, Batch 440/625 - Loss: 0.2944\n",
            "Epoch 4/10, Batch 450/625 - Loss: 0.3335\n",
            "Epoch 4/10, Batch 460/625 - Loss: 0.2526\n",
            "Epoch 4/10, Batch 470/625 - Loss: 0.3579\n",
            "Epoch 4/10, Batch 480/625 - Loss: 0.3213\n",
            "Epoch 4/10, Batch 490/625 - Loss: 0.2989\n",
            "Epoch 4/10, Batch 500/625 - Loss: 0.3057\n",
            "Epoch 4/10, Batch 510/625 - Loss: 0.3455\n",
            "Epoch 4/10, Batch 520/625 - Loss: 0.3141\n",
            "Epoch 4/10, Batch 530/625 - Loss: 0.2944\n",
            "Epoch 4/10, Batch 540/625 - Loss: 0.2388\n",
            "Epoch 4/10, Batch 550/625 - Loss: 0.2584\n",
            "Epoch 4/10, Batch 560/625 - Loss: 0.3135\n",
            "Epoch 4/10, Batch 570/625 - Loss: 0.3523\n",
            "Epoch 4/10, Batch 580/625 - Loss: 0.3261\n",
            "Epoch 4/10, Batch 590/625 - Loss: 0.3232\n",
            "Epoch 4/10, Batch 600/625 - Loss: 0.3171\n",
            "Epoch 4/10, Batch 610/625 - Loss: 0.2568\n",
            "Epoch 4/10, Batch 620/625 - Loss: 0.3336\n",
            "Epoch [4/10], Train Acc: 85.84%, Val Acc: 92.90%, Val Loss: 0.1778\n",
            "Epoch 5/10, Batch 0/625 - Loss: 0.0279\n",
            "Epoch 5/10, Batch 10/625 - Loss: 0.3192\n",
            "Epoch 5/10, Batch 20/625 - Loss: 0.2872\n",
            "Epoch 5/10, Batch 30/625 - Loss: 0.2697\n",
            "Epoch 5/10, Batch 40/625 - Loss: 0.3341\n",
            "Epoch 5/10, Batch 50/625 - Loss: 0.3048\n",
            "Epoch 5/10, Batch 60/625 - Loss: 0.2872\n",
            "Epoch 5/10, Batch 70/625 - Loss: 0.3111\n",
            "Epoch 5/10, Batch 80/625 - Loss: 0.2923\n",
            "Epoch 5/10, Batch 90/625 - Loss: 0.3338\n",
            "Epoch 5/10, Batch 100/625 - Loss: 0.2838\n",
            "Epoch 5/10, Batch 110/625 - Loss: 0.2786\n",
            "Epoch 5/10, Batch 120/625 - Loss: 0.2427\n",
            "Epoch 5/10, Batch 130/625 - Loss: 0.3249\n",
            "Epoch 5/10, Batch 140/625 - Loss: 0.2588\n",
            "Epoch 5/10, Batch 150/625 - Loss: 0.3237\n",
            "Epoch 5/10, Batch 160/625 - Loss: 0.2930\n",
            "Epoch 5/10, Batch 170/625 - Loss: 0.2479\n",
            "Epoch 5/10, Batch 180/625 - Loss: 0.3059\n",
            "Epoch 5/10, Batch 190/625 - Loss: 0.3035\n",
            "Epoch 5/10, Batch 200/625 - Loss: 0.3840\n",
            "Epoch 5/10, Batch 210/625 - Loss: 0.3268\n",
            "Epoch 5/10, Batch 220/625 - Loss: 0.2808\n",
            "Epoch 5/10, Batch 230/625 - Loss: 0.3193\n",
            "Epoch 5/10, Batch 240/625 - Loss: 0.3045\n",
            "Epoch 5/10, Batch 250/625 - Loss: 0.2653\n",
            "Epoch 5/10, Batch 260/625 - Loss: 0.3162\n",
            "Epoch 5/10, Batch 270/625 - Loss: 0.2529\n",
            "Epoch 5/10, Batch 280/625 - Loss: 0.3324\n",
            "Epoch 5/10, Batch 290/625 - Loss: 0.2897\n",
            "Epoch 5/10, Batch 300/625 - Loss: 0.3182\n",
            "Epoch 5/10, Batch 310/625 - Loss: 0.2958\n",
            "Epoch 5/10, Batch 320/625 - Loss: 0.2709\n",
            "Epoch 5/10, Batch 330/625 - Loss: 0.2898\n",
            "Epoch 5/10, Batch 340/625 - Loss: 0.2889\n",
            "Epoch 5/10, Batch 350/625 - Loss: 0.2432\n",
            "Epoch 5/10, Batch 360/625 - Loss: 0.2705\n",
            "Epoch 5/10, Batch 370/625 - Loss: 0.2891\n",
            "Epoch 5/10, Batch 380/625 - Loss: 0.2582\n",
            "Epoch 5/10, Batch 390/625 - Loss: 0.3191\n",
            "Epoch 5/10, Batch 400/625 - Loss: 0.3586\n",
            "Epoch 5/10, Batch 410/625 - Loss: 0.2681\n",
            "Epoch 5/10, Batch 420/625 - Loss: 0.3152\n",
            "Epoch 5/10, Batch 430/625 - Loss: 0.2865\n",
            "Epoch 5/10, Batch 440/625 - Loss: 0.3102\n",
            "Epoch 5/10, Batch 450/625 - Loss: 0.3062\n",
            "Epoch 5/10, Batch 460/625 - Loss: 0.2684\n",
            "Epoch 5/10, Batch 470/625 - Loss: 0.2822\n",
            "Epoch 5/10, Batch 480/625 - Loss: 0.3069\n",
            "Epoch 5/10, Batch 490/625 - Loss: 0.2777\n",
            "Epoch 5/10, Batch 500/625 - Loss: 0.2881\n",
            "Epoch 5/10, Batch 510/625 - Loss: 0.2942\n",
            "Epoch 5/10, Batch 520/625 - Loss: 0.3996\n",
            "Epoch 5/10, Batch 530/625 - Loss: 0.3004\n",
            "Epoch 5/10, Batch 540/625 - Loss: 0.3096\n",
            "Epoch 5/10, Batch 550/625 - Loss: 0.2912\n",
            "Epoch 5/10, Batch 560/625 - Loss: 0.3318\n",
            "Epoch 5/10, Batch 570/625 - Loss: 0.3010\n",
            "Epoch 5/10, Batch 580/625 - Loss: 0.2763\n",
            "Epoch 5/10, Batch 590/625 - Loss: 0.2710\n",
            "Epoch 5/10, Batch 600/625 - Loss: 0.3130\n",
            "Epoch 5/10, Batch 610/625 - Loss: 0.3057\n",
            "Epoch 5/10, Batch 620/625 - Loss: 0.2642\n",
            "Epoch [5/10], Train Acc: 86.78%, Val Acc: 93.78%, Val Loss: 0.1594\n",
            "Epoch 6/10, Batch 0/625 - Loss: 0.0276\n",
            "Epoch 6/10, Batch 10/625 - Loss: 0.2737\n",
            "Epoch 6/10, Batch 20/625 - Loss: 0.3273\n",
            "Epoch 6/10, Batch 30/625 - Loss: 0.2929\n",
            "Epoch 6/10, Batch 40/625 - Loss: 0.2775\n",
            "Epoch 6/10, Batch 50/625 - Loss: 0.2631\n",
            "Epoch 6/10, Batch 60/625 - Loss: 0.2542\n",
            "Epoch 6/10, Batch 70/625 - Loss: 0.2922\n",
            "Epoch 6/10, Batch 80/625 - Loss: 0.2650\n",
            "Epoch 6/10, Batch 90/625 - Loss: 0.2705\n",
            "Epoch 6/10, Batch 100/625 - Loss: 0.2740\n",
            "Epoch 6/10, Batch 110/625 - Loss: 0.2938\n",
            "Epoch 6/10, Batch 120/625 - Loss: 0.2833\n",
            "Epoch 6/10, Batch 130/625 - Loss: 0.2849\n",
            "Epoch 6/10, Batch 140/625 - Loss: 0.2573\n",
            "Epoch 6/10, Batch 150/625 - Loss: 0.3036\n",
            "Epoch 6/10, Batch 160/625 - Loss: 0.3474\n",
            "Epoch 6/10, Batch 170/625 - Loss: 0.2835\n",
            "Epoch 6/10, Batch 180/625 - Loss: 0.2611\n",
            "Epoch 6/10, Batch 190/625 - Loss: 0.2731\n",
            "Epoch 6/10, Batch 200/625 - Loss: 0.2876\n",
            "Epoch 6/10, Batch 210/625 - Loss: 0.3470\n",
            "Epoch 6/10, Batch 220/625 - Loss: 0.2841\n",
            "Epoch 6/10, Batch 230/625 - Loss: 0.2626\n",
            "Epoch 6/10, Batch 240/625 - Loss: 0.3060\n",
            "Epoch 6/10, Batch 250/625 - Loss: 0.2588\n",
            "Epoch 6/10, Batch 260/625 - Loss: 0.2550\n",
            "Epoch 6/10, Batch 270/625 - Loss: 0.2637\n",
            "Epoch 6/10, Batch 280/625 - Loss: 0.2841\n",
            "Epoch 6/10, Batch 290/625 - Loss: 0.2563\n",
            "Epoch 6/10, Batch 300/625 - Loss: 0.3242\n",
            "Epoch 6/10, Batch 310/625 - Loss: 0.2337\n",
            "Epoch 6/10, Batch 320/625 - Loss: 0.3282\n",
            "Epoch 6/10, Batch 330/625 - Loss: 0.2761\n",
            "Epoch 6/10, Batch 340/625 - Loss: 0.3238\n",
            "Epoch 6/10, Batch 350/625 - Loss: 0.2849\n",
            "Epoch 6/10, Batch 360/625 - Loss: 0.2583\n",
            "Epoch 6/10, Batch 370/625 - Loss: 0.2990\n",
            "Epoch 6/10, Batch 380/625 - Loss: 0.3060\n",
            "Epoch 6/10, Batch 390/625 - Loss: 0.2745\n",
            "Epoch 6/10, Batch 400/625 - Loss: 0.2630\n",
            "Epoch 6/10, Batch 410/625 - Loss: 0.2496\n",
            "Epoch 6/10, Batch 420/625 - Loss: 0.2817\n",
            "Epoch 6/10, Batch 430/625 - Loss: 0.2228\n",
            "Epoch 6/10, Batch 440/625 - Loss: 0.2474\n",
            "Epoch 6/10, Batch 450/625 - Loss: 0.2804\n",
            "Epoch 6/10, Batch 460/625 - Loss: 0.2613\n",
            "Epoch 6/10, Batch 470/625 - Loss: 0.2551\n",
            "Epoch 6/10, Batch 480/625 - Loss: 0.2810\n",
            "Epoch 6/10, Batch 490/625 - Loss: 0.2577\n",
            "Epoch 6/10, Batch 500/625 - Loss: 0.2654\n",
            "Epoch 6/10, Batch 510/625 - Loss: 0.2515\n",
            "Epoch 6/10, Batch 520/625 - Loss: 0.3096\n",
            "Epoch 6/10, Batch 530/625 - Loss: 0.3281\n",
            "Epoch 6/10, Batch 540/625 - Loss: 0.2860\n",
            "Epoch 6/10, Batch 550/625 - Loss: 0.2963\n",
            "Epoch 6/10, Batch 560/625 - Loss: 0.2463\n",
            "Epoch 6/10, Batch 570/625 - Loss: 0.2356\n",
            "Epoch 6/10, Batch 580/625 - Loss: 0.2976\n",
            "Epoch 6/10, Batch 590/625 - Loss: 0.2355\n",
            "Epoch 6/10, Batch 600/625 - Loss: 0.2891\n",
            "Epoch 6/10, Batch 610/625 - Loss: 0.2818\n",
            "Epoch 6/10, Batch 620/625 - Loss: 0.2436\n",
            "Epoch [6/10], Train Acc: 87.42%, Val Acc: 92.72%, Val Loss: 0.1686\n",
            "Epoch 7/10, Batch 0/625 - Loss: 0.0204\n",
            "Epoch 7/10, Batch 10/625 - Loss: 0.2362\n",
            "Epoch 7/10, Batch 20/625 - Loss: 0.3097\n",
            "Epoch 7/10, Batch 30/625 - Loss: 0.2614\n",
            "Epoch 7/10, Batch 40/625 - Loss: 0.2723\n",
            "Epoch 7/10, Batch 50/625 - Loss: 0.2747\n",
            "Epoch 7/10, Batch 60/625 - Loss: 0.2145\n",
            "Epoch 7/10, Batch 70/625 - Loss: 0.2175\n",
            "Epoch 7/10, Batch 80/625 - Loss: 0.2772\n",
            "Epoch 7/10, Batch 90/625 - Loss: 0.2046\n",
            "Epoch 7/10, Batch 100/625 - Loss: 0.2370\n",
            "Epoch 7/10, Batch 110/625 - Loss: 0.2254\n",
            "Epoch 7/10, Batch 120/625 - Loss: 0.2679\n",
            "Epoch 7/10, Batch 130/625 - Loss: 0.2357\n",
            "Epoch 7/10, Batch 140/625 - Loss: 0.2567\n",
            "Epoch 7/10, Batch 150/625 - Loss: 0.2345\n",
            "Epoch 7/10, Batch 160/625 - Loss: 0.2117\n",
            "Epoch 7/10, Batch 170/625 - Loss: 0.2963\n",
            "Epoch 7/10, Batch 180/625 - Loss: 0.2739\n",
            "Epoch 7/10, Batch 190/625 - Loss: 0.2724\n",
            "Epoch 7/10, Batch 200/625 - Loss: 0.2585\n",
            "Epoch 7/10, Batch 210/625 - Loss: 0.2680\n",
            "Epoch 7/10, Batch 220/625 - Loss: 0.2349\n",
            "Epoch 7/10, Batch 230/625 - Loss: 0.2151\n",
            "Epoch 7/10, Batch 240/625 - Loss: 0.2055\n",
            "Epoch 7/10, Batch 250/625 - Loss: 0.2408\n",
            "Epoch 7/10, Batch 260/625 - Loss: 0.2805\n",
            "Epoch 7/10, Batch 270/625 - Loss: 0.2466\n",
            "Epoch 7/10, Batch 280/625 - Loss: 0.2624\n",
            "Epoch 7/10, Batch 290/625 - Loss: 0.2241\n",
            "Epoch 7/10, Batch 300/625 - Loss: 0.1907\n",
            "Epoch 7/10, Batch 310/625 - Loss: 0.2453\n",
            "Epoch 7/10, Batch 320/625 - Loss: 0.2502\n",
            "Epoch 7/10, Batch 330/625 - Loss: 0.2686\n",
            "Epoch 7/10, Batch 340/625 - Loss: 0.2615\n",
            "Epoch 7/10, Batch 350/625 - Loss: 0.2470\n",
            "Epoch 7/10, Batch 360/625 - Loss: 0.2877\n",
            "Epoch 7/10, Batch 370/625 - Loss: 0.2744\n",
            "Epoch 7/10, Batch 380/625 - Loss: 0.2843\n",
            "Epoch 7/10, Batch 390/625 - Loss: 0.2669\n",
            "Epoch 7/10, Batch 400/625 - Loss: 0.2395\n",
            "Epoch 7/10, Batch 410/625 - Loss: 0.2727\n",
            "Epoch 7/10, Batch 420/625 - Loss: 0.2477\n",
            "Epoch 7/10, Batch 430/625 - Loss: 0.2904\n",
            "Epoch 7/10, Batch 440/625 - Loss: 0.2646\n",
            "Epoch 7/10, Batch 450/625 - Loss: 0.3171\n",
            "Epoch 7/10, Batch 460/625 - Loss: 0.2529\n",
            "Epoch 7/10, Batch 470/625 - Loss: 0.2706\n",
            "Epoch 7/10, Batch 480/625 - Loss: 0.2082\n",
            "Epoch 7/10, Batch 490/625 - Loss: 0.2634\n",
            "Epoch 7/10, Batch 500/625 - Loss: 0.1785\n",
            "Epoch 7/10, Batch 510/625 - Loss: 0.2634\n",
            "Epoch 7/10, Batch 520/625 - Loss: 0.2660\n",
            "Epoch 7/10, Batch 530/625 - Loss: 0.2833\n",
            "Epoch 7/10, Batch 540/625 - Loss: 0.2173\n",
            "Epoch 7/10, Batch 550/625 - Loss: 0.3259\n",
            "Epoch 7/10, Batch 560/625 - Loss: 0.2145\n",
            "Epoch 7/10, Batch 570/625 - Loss: 0.2895\n",
            "Epoch 7/10, Batch 580/625 - Loss: 0.2395\n",
            "Epoch 7/10, Batch 590/625 - Loss: 0.2289\n",
            "Epoch 7/10, Batch 600/625 - Loss: 0.2523\n",
            "Epoch 7/10, Batch 610/625 - Loss: 0.2169\n",
            "Epoch 7/10, Batch 620/625 - Loss: 0.2271\n",
            "Epoch [7/10], Train Acc: 88.99%, Val Acc: 94.78%, Val Loss: 0.1288\n",
            "Epoch 8/10, Batch 0/625 - Loss: 0.0133\n",
            "Epoch 8/10, Batch 10/625 - Loss: 0.2470\n",
            "Epoch 8/10, Batch 20/625 - Loss: 0.2040\n",
            "Epoch 8/10, Batch 30/625 - Loss: 0.2750\n",
            "Epoch 8/10, Batch 40/625 - Loss: 0.1635\n",
            "Epoch 8/10, Batch 50/625 - Loss: 0.2066\n",
            "Epoch 8/10, Batch 60/625 - Loss: 0.2183\n",
            "Epoch 8/10, Batch 70/625 - Loss: 0.2625\n",
            "Epoch 8/10, Batch 80/625 - Loss: 0.2181\n",
            "Epoch 8/10, Batch 90/625 - Loss: 0.2075\n",
            "Epoch 8/10, Batch 100/625 - Loss: 0.2133\n",
            "Epoch 8/10, Batch 110/625 - Loss: 0.2725\n",
            "Epoch 8/10, Batch 120/625 - Loss: 0.2289\n",
            "Epoch 8/10, Batch 130/625 - Loss: 0.2095\n",
            "Epoch 8/10, Batch 140/625 - Loss: 0.1955\n",
            "Epoch 8/10, Batch 150/625 - Loss: 0.2335\n",
            "Epoch 8/10, Batch 160/625 - Loss: 0.2269\n",
            "Epoch 8/10, Batch 170/625 - Loss: 0.2353\n",
            "Epoch 8/10, Batch 180/625 - Loss: 0.2052\n",
            "Epoch 8/10, Batch 190/625 - Loss: 0.2384\n",
            "Epoch 8/10, Batch 200/625 - Loss: 0.2295\n",
            "Epoch 8/10, Batch 210/625 - Loss: 0.1748\n",
            "Epoch 8/10, Batch 220/625 - Loss: 0.2478\n",
            "Epoch 8/10, Batch 230/625 - Loss: 0.2245\n",
            "Epoch 8/10, Batch 240/625 - Loss: 0.2210\n",
            "Epoch 8/10, Batch 250/625 - Loss: 0.2156\n",
            "Epoch 8/10, Batch 260/625 - Loss: 0.1852\n",
            "Epoch 8/10, Batch 270/625 - Loss: 0.2245\n",
            "Epoch 8/10, Batch 280/625 - Loss: 0.2317\n",
            "Epoch 8/10, Batch 290/625 - Loss: 0.2470\n",
            "Epoch 8/10, Batch 300/625 - Loss: 0.3154\n",
            "Epoch 8/10, Batch 310/625 - Loss: 0.2607\n",
            "Epoch 8/10, Batch 320/625 - Loss: 0.2595\n",
            "Epoch 8/10, Batch 330/625 - Loss: 0.3143\n",
            "Epoch 8/10, Batch 340/625 - Loss: 0.2177\n",
            "Epoch 8/10, Batch 350/625 - Loss: 0.2378\n",
            "Epoch 8/10, Batch 360/625 - Loss: 0.2597\n",
            "Epoch 8/10, Batch 370/625 - Loss: 0.2405\n",
            "Epoch 8/10, Batch 380/625 - Loss: 0.2477\n",
            "Epoch 8/10, Batch 390/625 - Loss: 0.2286\n",
            "Epoch 8/10, Batch 400/625 - Loss: 0.2814\n",
            "Epoch 8/10, Batch 410/625 - Loss: 0.2669\n",
            "Epoch 8/10, Batch 420/625 - Loss: 0.2347\n",
            "Epoch 8/10, Batch 430/625 - Loss: 0.2525\n",
            "Epoch 8/10, Batch 440/625 - Loss: 0.2074\n",
            "Epoch 8/10, Batch 450/625 - Loss: 0.2063\n",
            "Epoch 8/10, Batch 460/625 - Loss: 0.1841\n",
            "Epoch 8/10, Batch 470/625 - Loss: 0.2633\n",
            "Epoch 8/10, Batch 480/625 - Loss: 0.2394\n",
            "Epoch 8/10, Batch 490/625 - Loss: 0.2388\n",
            "Epoch 8/10, Batch 500/625 - Loss: 0.2148\n",
            "Epoch 8/10, Batch 510/625 - Loss: 0.2258\n",
            "Epoch 8/10, Batch 520/625 - Loss: 0.2412\n",
            "Epoch 8/10, Batch 530/625 - Loss: 0.2208\n",
            "Epoch 8/10, Batch 540/625 - Loss: 0.2079\n",
            "Epoch 8/10, Batch 550/625 - Loss: 0.2587\n",
            "Epoch 8/10, Batch 560/625 - Loss: 0.2343\n",
            "Epoch 8/10, Batch 570/625 - Loss: 0.2112\n",
            "Epoch 8/10, Batch 580/625 - Loss: 0.1931\n",
            "Epoch 8/10, Batch 590/625 - Loss: 0.1954\n",
            "Epoch 8/10, Batch 600/625 - Loss: 0.2976\n",
            "Epoch 8/10, Batch 610/625 - Loss: 0.2395\n",
            "Epoch 8/10, Batch 620/625 - Loss: 0.2211\n",
            "Epoch [8/10], Train Acc: 89.98%, Val Acc: 94.98%, Val Loss: 0.1226\n",
            "Epoch 9/10, Batch 0/625 - Loss: 0.0210\n",
            "Epoch 9/10, Batch 10/625 - Loss: 0.2317\n",
            "Epoch 9/10, Batch 20/625 - Loss: 0.2109\n",
            "Epoch 9/10, Batch 30/625 - Loss: 0.1920\n",
            "Epoch 9/10, Batch 40/625 - Loss: 0.2025\n",
            "Epoch 9/10, Batch 50/625 - Loss: 0.2184\n",
            "Epoch 9/10, Batch 60/625 - Loss: 0.2599\n",
            "Epoch 9/10, Batch 70/625 - Loss: 0.2734\n",
            "Epoch 9/10, Batch 80/625 - Loss: 0.2524\n",
            "Epoch 9/10, Batch 90/625 - Loss: 0.2308\n",
            "Epoch 9/10, Batch 100/625 - Loss: 0.2612\n",
            "Epoch 9/10, Batch 110/625 - Loss: 0.2495\n",
            "Epoch 9/10, Batch 120/625 - Loss: 0.2529\n",
            "Epoch 9/10, Batch 130/625 - Loss: 0.2400\n",
            "Epoch 9/10, Batch 140/625 - Loss: 0.2369\n",
            "Epoch 9/10, Batch 150/625 - Loss: 0.1919\n",
            "Epoch 9/10, Batch 160/625 - Loss: 0.2213\n",
            "Epoch 9/10, Batch 170/625 - Loss: 0.2264\n",
            "Epoch 9/10, Batch 180/625 - Loss: 0.1544\n",
            "Epoch 9/10, Batch 190/625 - Loss: 0.2167\n",
            "Epoch 9/10, Batch 200/625 - Loss: 0.1992\n",
            "Epoch 9/10, Batch 210/625 - Loss: 0.1898\n",
            "Epoch 9/10, Batch 220/625 - Loss: 0.2333\n",
            "Epoch 9/10, Batch 230/625 - Loss: 0.2495\n",
            "Epoch 9/10, Batch 240/625 - Loss: 0.2126\n",
            "Epoch 9/10, Batch 250/625 - Loss: 0.2524\n",
            "Epoch 9/10, Batch 260/625 - Loss: 0.2258\n",
            "Epoch 9/10, Batch 270/625 - Loss: 0.2430\n",
            "Epoch 9/10, Batch 280/625 - Loss: 0.2184\n",
            "Epoch 9/10, Batch 290/625 - Loss: 0.1972\n",
            "Epoch 9/10, Batch 300/625 - Loss: 0.2237\n",
            "Epoch 9/10, Batch 310/625 - Loss: 0.2217\n",
            "Epoch 9/10, Batch 320/625 - Loss: 0.2148\n",
            "Epoch 9/10, Batch 330/625 - Loss: 0.2539\n",
            "Epoch 9/10, Batch 340/625 - Loss: 0.2242\n",
            "Epoch 9/10, Batch 350/625 - Loss: 0.2172\n",
            "Epoch 9/10, Batch 360/625 - Loss: 0.2655\n",
            "Epoch 9/10, Batch 370/625 - Loss: 0.2565\n",
            "Epoch 9/10, Batch 380/625 - Loss: 0.1900\n",
            "Epoch 9/10, Batch 390/625 - Loss: 0.2144\n",
            "Epoch 9/10, Batch 400/625 - Loss: 0.2053\n",
            "Epoch 9/10, Batch 410/625 - Loss: 0.1945\n",
            "Epoch 9/10, Batch 420/625 - Loss: 0.2660\n",
            "Epoch 9/10, Batch 430/625 - Loss: 0.2239\n",
            "Epoch 9/10, Batch 440/625 - Loss: 0.2396\n",
            "Epoch 9/10, Batch 450/625 - Loss: 0.2208\n",
            "Epoch 9/10, Batch 460/625 - Loss: 0.2137\n",
            "Epoch 9/10, Batch 470/625 - Loss: 0.2123\n",
            "Epoch 9/10, Batch 480/625 - Loss: 0.2331\n",
            "Epoch 9/10, Batch 490/625 - Loss: 0.2086\n",
            "Epoch 9/10, Batch 500/625 - Loss: 0.2051\n",
            "Epoch 9/10, Batch 510/625 - Loss: 0.2003\n",
            "Epoch 9/10, Batch 520/625 - Loss: 0.2772\n",
            "Epoch 9/10, Batch 530/625 - Loss: 0.1772\n",
            "Epoch 9/10, Batch 540/625 - Loss: 0.1838\n",
            "Epoch 9/10, Batch 550/625 - Loss: 0.2024\n",
            "Epoch 9/10, Batch 560/625 - Loss: 0.2521\n",
            "Epoch 9/10, Batch 570/625 - Loss: 0.2420\n",
            "Epoch 9/10, Batch 580/625 - Loss: 0.2427\n",
            "Epoch 9/10, Batch 590/625 - Loss: 0.2257\n",
            "Epoch 9/10, Batch 600/625 - Loss: 0.1922\n",
            "Epoch 9/10, Batch 610/625 - Loss: 0.2066\n",
            "Epoch 9/10, Batch 620/625 - Loss: 0.2170\n",
            "Epoch [9/10], Train Acc: 90.23%, Val Acc: 95.44%, Val Loss: 0.1094\n",
            "Epoch 10/10, Batch 0/625 - Loss: 0.0282\n",
            "Epoch 10/10, Batch 10/625 - Loss: 0.2574\n",
            "Epoch 10/10, Batch 20/625 - Loss: 0.1912\n",
            "Epoch 10/10, Batch 30/625 - Loss: 0.1807\n",
            "Epoch 10/10, Batch 40/625 - Loss: 0.1907\n",
            "Epoch 10/10, Batch 50/625 - Loss: 0.1915\n",
            "Epoch 10/10, Batch 60/625 - Loss: 0.2191\n",
            "Epoch 10/10, Batch 70/625 - Loss: 0.2136\n",
            "Epoch 10/10, Batch 80/625 - Loss: 0.2095\n",
            "Epoch 10/10, Batch 90/625 - Loss: 0.2598\n",
            "Epoch 10/10, Batch 100/625 - Loss: 0.2212\n",
            "Epoch 10/10, Batch 110/625 - Loss: 0.2342\n",
            "Epoch 10/10, Batch 120/625 - Loss: 0.1779\n",
            "Epoch 10/10, Batch 130/625 - Loss: 0.1885\n",
            "Epoch 10/10, Batch 140/625 - Loss: 0.1824\n",
            "Epoch 10/10, Batch 150/625 - Loss: 0.2450\n",
            "Epoch 10/10, Batch 160/625 - Loss: 0.1956\n",
            "Epoch 10/10, Batch 170/625 - Loss: 0.1997\n",
            "Epoch 10/10, Batch 180/625 - Loss: 0.2311\n",
            "Epoch 10/10, Batch 190/625 - Loss: 0.1820\n",
            "Epoch 10/10, Batch 200/625 - Loss: 0.1902\n",
            "Epoch 10/10, Batch 210/625 - Loss: 0.2491\n",
            "Epoch 10/10, Batch 220/625 - Loss: 0.2169\n",
            "Epoch 10/10, Batch 230/625 - Loss: 0.2067\n",
            "Epoch 10/10, Batch 240/625 - Loss: 0.2180\n",
            "Epoch 10/10, Batch 250/625 - Loss: 0.2155\n",
            "Epoch 10/10, Batch 260/625 - Loss: 0.2503\n",
            "Epoch 10/10, Batch 270/625 - Loss: 0.2202\n",
            "Epoch 10/10, Batch 280/625 - Loss: 0.2554\n",
            "Epoch 10/10, Batch 290/625 - Loss: 0.2301\n",
            "Epoch 10/10, Batch 300/625 - Loss: 0.1918\n",
            "Epoch 10/10, Batch 310/625 - Loss: 0.2005\n",
            "Epoch 10/10, Batch 320/625 - Loss: 0.2299\n",
            "Epoch 10/10, Batch 330/625 - Loss: 0.1976\n",
            "Epoch 10/10, Batch 340/625 - Loss: 0.2054\n",
            "Epoch 10/10, Batch 350/625 - Loss: 0.1745\n",
            "Epoch 10/10, Batch 360/625 - Loss: 0.2195\n",
            "Epoch 10/10, Batch 370/625 - Loss: 0.2610\n",
            "Epoch 10/10, Batch 380/625 - Loss: 0.2369\n",
            "Epoch 10/10, Batch 390/625 - Loss: 0.2497\n",
            "Epoch 10/10, Batch 400/625 - Loss: 0.2575\n",
            "Epoch 10/10, Batch 410/625 - Loss: 0.1605\n",
            "Epoch 10/10, Batch 420/625 - Loss: 0.2012\n",
            "Epoch 10/10, Batch 430/625 - Loss: 0.1832\n",
            "Epoch 10/10, Batch 440/625 - Loss: 0.2099\n",
            "Epoch 10/10, Batch 450/625 - Loss: 0.2025\n",
            "Epoch 10/10, Batch 460/625 - Loss: 0.2080\n",
            "Epoch 10/10, Batch 470/625 - Loss: 0.1931\n",
            "Epoch 10/10, Batch 480/625 - Loss: 0.2271\n",
            "Epoch 10/10, Batch 490/625 - Loss: 0.1828\n",
            "Epoch 10/10, Batch 500/625 - Loss: 0.2395\n",
            "Epoch 10/10, Batch 510/625 - Loss: 0.2221\n",
            "Epoch 10/10, Batch 520/625 - Loss: 0.2330\n",
            "Epoch 10/10, Batch 530/625 - Loss: 0.2049\n",
            "Epoch 10/10, Batch 540/625 - Loss: 0.2714\n",
            "Epoch 10/10, Batch 550/625 - Loss: 0.2186\n",
            "Epoch 10/10, Batch 560/625 - Loss: 0.2014\n",
            "Epoch 10/10, Batch 570/625 - Loss: 0.2657\n",
            "Epoch 10/10, Batch 580/625 - Loss: 0.2113\n",
            "Epoch 10/10, Batch 590/625 - Loss: 0.1718\n",
            "Epoch 10/10, Batch 600/625 - Loss: 0.2193\n",
            "Epoch 10/10, Batch 610/625 - Loss: 0.2291\n",
            "Epoch 10/10, Batch 620/625 - Loss: 0.1863\n",
            "Epoch [10/10], Train Acc: 90.40%, Val Acc: 95.58%, Val Loss: 0.1074\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_acc, val_acc = train_model(model, criterion, optimizer, train_loader, val_loader,scheduler,epochs=10)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a7P-QnKG4F-a"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jarn0t2v3uBR",
        "outputId": "1ef48be6-3106-4812-87e5-1a4087231269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n",
            "Probabilities: [0.479 0.521]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3d7282bd08f6>:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():  # Mixed precision for faster inference\n",
            "<ipython-input-7-dce7cf042faa>:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        }
      ],
      "source": [
        "# Define the validation transformations (same as used during validation)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path ='/content/dogtesterdogvscat.jfifp'   # Path to your image\n",
        "image = Image.open('/content/dogtesterdogvscat.jfif')\n",
        "image = val_transforms(image)\n",
        "image = image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Send the image to the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "image = image.to(device)\n",
        "\n",
        "# Load your trained model and move it to the device\n",
        "model = CNNModel(pretrained=True, num_unfreeze_layers=31)  # Initialize model\n",
        "model = model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    with amp.autocast():  # Mixed precision for faster inference\n",
        "        output = model(image)\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = torch.softmax(output, dim=1)\n",
        "\n",
        "# Get the predicted class\n",
        "predicted_class = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class.item()}\")\n",
        "print(f\"Probabilities: {probabilities.cpu().numpy()[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GSX5P1DfYgj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}