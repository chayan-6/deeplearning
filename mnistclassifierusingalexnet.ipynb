{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-sql==0.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzRLq3e495tf",
        "outputId": "8550d76b-ddeb-456b-c193-0c0f52dcecb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-sql==0.4.1\n",
            "  Downloading ipython_sql-0.4.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting prettytable<1 (from ipython-sql==0.4.1)\n",
            "  Downloading prettytable-0.7.2.zip (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython>=1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (7.34.0)\n",
            "Requirement already satisfied: sqlalchemy>=0.6.7 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (2.0.34)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql==0.4.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=1.0->ipython-sql==0.4.1)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.6.7->ipython-sql==0.4.1) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.6.7->ipython-sql==0.4.1) (3.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=1.0->ipython-sql==0.4.1) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=1.0->ipython-sql==0.4.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql==0.4.1) (0.2.13)\n",
            "Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Building wheels for collected packages: prettytable\n",
            "  Building wheel for prettytable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13696 sha256=f9bd7de8f43842487f6472bd491799058dbaee8adcb9ab7d7da46540158e01f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/4b/07/18c5d92824315576e478206ea69df34a9e31958f6143eb0e31\n",
            "Successfully built prettytable\n",
            "Installing collected packages: prettytable, jedi, ipython-sql\n",
            "  Attempting uninstall: prettytable\n",
            "    Found existing installation: prettytable 3.11.0\n",
            "    Uninstalling prettytable-3.11.0:\n",
            "      Successfully uninstalled prettytable-3.11.0\n",
            "  Attempting uninstall: ipython-sql\n",
            "    Found existing installation: ipython-sql 0.5.0\n",
            "    Uninstalling ipython-sql-0.5.0:\n",
            "      Successfully uninstalled ipython-sql-0.5.0\n",
            "Successfully installed ipython-sql-0.4.1 jedi-0.19.1 prettytable-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGYUME8C6xfC",
        "outputId": "16eee793-750d-4e51-e4df-2b880f362e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This program is a partial MNIST classifier using AlexNet. It accepts three parameters provided as a command line input. The first two inputs are two digits between 0-9 which are used to train and test the classifier and the third parameter controls the number of training epochs.\n",
        "Syntax: python assignment.py <number> <number> <number>\n",
        "\n",
        "For example, to train and test AlexNet with 1 and 2 MNIST samples with 4 training epochs, the command line input should be:\n",
        "python assignment.py 1 2 4\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "ALERT: * * * No changes are allowed to import statements  * * *\n",
        "\"\"\"\n",
        "%%writefile example_template.py\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "* * * Changes allowed from here  * * *\n",
        "\"\"\"\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            # Define feature extractor here...\n",
        "              nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),  # Conv2D 32 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Conv2D 64 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),                  # MaxPool 2x2\n",
        "            nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1),  # Conv2D 96 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 64, kernel_size=3, stride=1, padding=1),  # Conv2D 64 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),  # Conv2D 32 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            # Define classifier here...\n",
        "              nn.Dropout(),\n",
        "            nn.Linear(32 * 13 * 13, 2048),  # 32 * 13 * 13 = 4608 input features\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 10)  # 10 output features for 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define forward network 'x' that combines feature extractor and classifier\n",
        "        x = self.feature(x)  # Pass through the feature extractor\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.classifier(x)  # Pass through the classifier\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "ALERT: * * * No changes are allowed after this comment  * * *\n",
        "\"\"\"\n",
        "\n",
        "def load_subset(full_train_set, full_test_set, label_one, label_two):\n",
        "    # Sample the correct train labels\n",
        "    train_set = []\n",
        "    data_lim = 20000\n",
        "    for data in full_train_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                train_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    test_set = []\n",
        "    data_lim = 1000\n",
        "    for data in full_test_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                test_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return train_set, test_set\n",
        "\n",
        "def train(model,optimizer,train_loader,epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()#size_average=False\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
        "    test_accuracy = (acc / len(test_loader.dataset))\n",
        "    return test_accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    if len(sys.argv) == 3:\n",
        "        print(\"Usage: python assignment.py <number> <number>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    input_data_one = sys.argv[1].strip()\n",
        "    input_data_two = sys.argv[2].strip()\n",
        "    epochs = sys.argv[3].strip()\n",
        "\n",
        "    \"\"\"  Call to function that will perform the computation. \"\"\"\n",
        "    if input_data_one.isdigit() and input_data_two.isdigit() and epochs.isdigit():\n",
        "\n",
        "        label_one = int(input_data_one)\n",
        "        label_two = int(input_data_two)\n",
        "        epochs = int(epochs)\n",
        "\n",
        "        if label_one!=label_two and 0<=label_one<=9 and 0<=label_two<=9:\n",
        "            torch.manual_seed(42)\n",
        "            # Load MNIST dataset\n",
        "            trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "            full_train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
        "            full_test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
        "            batch_size = 16\n",
        "            # Get final train and test sets\n",
        "            train_set, test_set = load_subset(full_train_set,full_test_set,label_one,label_two)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=False)\n",
        "            test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "            model = AlexNet()\n",
        "            if torch.cuda.is_available():\n",
        "                model.cuda()\n",
        "\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "            for epoch in range(1, epochs+1):\n",
        "                train(model,optimizer,train_loader,epoch)\n",
        "                accuracy = test(model,test_loader)\n",
        "\n",
        "            print(round(accuracy,2))\n",
        "\n",
        "\n",
        "        else:\n",
        "           print(\"Invalid input\")\n",
        "    else:\n",
        "        print(\"Invalid input\")\n",
        "\n",
        "\n",
        "    \"\"\" End to call \"\"\""
      ]
    }
  ]
}